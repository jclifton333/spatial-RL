results:
  0: {runtime: 622.0370073318481, score: 0.34115384615384614}
  1: {runtime: 620.4869868755341, score: 0.3819230769230769}
  2: {runtime: 621.4196925163269, score: 0.35615384615384615}
  3: {runtime: 620.0643117427826, score: 0.37884615384615383}
  4: {runtime: 621.4396743774414, score: 0.4503846153846154}
  5: {runtime: 620.7437479496002, score: 0.3646153846153846}
  6: {runtime: 619.6983342170715, score: 0.3780769230769231}
  7: {runtime: 621.2741873264313, score: 0.35923076923076924}
  8: {runtime: 619.6238164901733, score: 0.3973076923076923}
  9: {runtime: 619.7007150650024, score: 0.3219230769230769}
  10: {runtime: 617.7236483097076, score: 0.3903846153846154}
  11: {runtime: 622.8353915214539, score: 0.4065384615384615}
  12: {runtime: 621.2083568572998, score: 0.3465384615384615}
  13: {runtime: 620.6894061565399, score: 0.4096153846153846}
  14: {runtime: 619.4889869689941, score: 0.32653846153846156}
  15: {runtime: 621.6213252544403, score: 0.36}
  16: {runtime: 619.6152377128601, score: 0.3119230769230769}
  17: {runtime: 621.0842690467834, score: 0.38269230769230766}
  18: {runtime: 621.82599568367, score: 0.37615384615384617}
  19: {runtime: 621.5104053020477, score: 0.3465384615384615}
  20: {runtime: 619.5032186508179, score: 0.24923076923076923}
  21: {runtime: 621.1614294052124, score: 0.36615384615384616}
  22: {runtime: 622.7353065013885, score: 0.37346153846153846}
  23: {runtime: 620.136067867279, score: 0.39653846153846156}
  24: {runtime: 668.2197830677032, score: 0.41115384615384615}
  25: {runtime: 619.5913183689117, score: 0.36}
  26: {runtime: 621.5211637020111, score: 0.3680769230769231}
  27: {runtime: 663.0622246265411, score: 0.4023076923076923}
  28: {runtime: 621.2107980251312, score: 0.37961538461538463}
  29: {runtime: 621.22878241539, score: 0.385}
  30: {runtime: 620.0902464389801, score: 0.2026923076923077}
  31: {runtime: 619.0133638381958, score: 0.3515384615384615}
  32: {runtime: 621.3191707134247, score: 0.2692307692307692}
  33: {runtime: 663.4272651672363, score: 0.36153846153846153}
  34: {runtime: 621.7472128868103, score: 0.3669230769230769}
  35: {runtime: 620.6576747894287, score: 0.44153846153846155}
  36: {runtime: 621.9526553153992, score: 0.285}
  37: {runtime: 619.8924460411072, score: 0.36115384615384616}
  38: {runtime: 659.2874927520752, score: 0.4323076923076923}
  39: {runtime: 620.7458748817444, score: 0.44653846153846155}
  40: {runtime: 620.8291034698486, score: 0.4519230769230769}
  41: {runtime: 619.9729204177856, score: 0.245}
  42: {runtime: 619.8849568367004, score: 0.35192307692307695}
  43: {runtime: 619.9597866535187, score: 0.39115384615384613}
  44: {runtime: 621.4100677967072, score: 0.39076923076923076}
  45: {runtime: 621.2248630523682, score: 0.2423076923076923}
  46: {runtime: 621.3140668869019, score: 0.3996153846153846}
  47: {runtime: 620.0245621204376, score: 0.38346153846153846}
  48: {runtime: 312.9184744358063, score: 0.39884615384615385}
  49: {runtime: 313.41552567481995, score: 0.41}
  mean: 0.3652307692307693
  se: !!python/object/apply:numpy.core.multiarray.scalar
  - !!python/object/apply:numpy.dtype
    args: [f8, 0, 1]
    state: !!python/tuple [3, <, null, null, null, -1, -1, 0]
  - !!binary |
    nD/Zxq3ofj8=
settings: {L: 100, argmaxer: quad_approx, argmaxer_name: quad_approx, classifier: KerasLogit,
  divide_evenly: false, env_name: sis, evaluation_budget: 100, gamma: 0.9, number_of_replicates: 50,
  planning_depth: 25, policy_name: rollout, regressor: KerasRegressor, rollout_depth: 1,
  time_horizon: 25, treatment_budget: 5}
