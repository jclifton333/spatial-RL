results:
  0: {runtime: 302.21797823905945, score: 0.37}
  1: {runtime: 304.99210953712463, score: 0.31461538461538463}
  2: {runtime: 301.5230963230133, score: 0.35923076923076924}
  3: {runtime: 288.8100161552429, score: 0.30615384615384617}
  4: {runtime: 289.2417457103729, score: 0.1946153846153846}
  5: {runtime: 301.78522634506226, score: 0.38769230769230767}
  6: {runtime: 302.23842000961304, score: 0.37153846153846154}
  7: {runtime: 303.11905217170715, score: 0.31384615384615383}
  8: {runtime: 297.91046142578125, score: 0.25769230769230766}
  9: {runtime: 301.91630840301514, score: 0.32461538461538464}
  10: {runtime: 301.73832511901855, score: 0.24615384615384617}
  11: {runtime: 302.5801067352295, score: 0.31}
  12: {runtime: 303.44899797439575, score: 0.3823076923076923}
  13: {runtime: 302.910710811615, score: 0.36230769230769233}
  14: {runtime: 288.96295142173767, score: 0.43923076923076926}
  15: {runtime: 303.5369141101837, score: 0.3269230769230769}
  16: {runtime: 297.21460485458374, score: 0.37}
  17: {runtime: 302.7621557712555, score: 0.3007692307692308}
  18: {runtime: 288.0224311351776, score: 0.3861538461538462}
  19: {runtime: 299.65437030792236, score: 0.43615384615384617}
  20: {runtime: 303.62586069107056, score: 0.23692307692307693}
  21: {runtime: 300.2095191478729, score: 0.38076923076923075}
  22: {runtime: 302.4507863521576, score: 0.42153846153846153}
  23: {runtime: 288.6366605758667, score: 0.37538461538461537}
  24: {runtime: 302.3111069202423, score: 0.20384615384615384}
  25: {runtime: 302.86520624160767, score: 0.27}
  26: {runtime: 302.70289301872253, score: 0.33}
  27: {runtime: 303.3252229690552, score: 0.22384615384615383}
  28: {runtime: 288.7735481262207, score: 0.42230769230769233}
  29: {runtime: 301.4217224121094, score: 0.43538461538461537}
  30: {runtime: 303.452919960022, score: 0.3946153846153846}
  31: {runtime: 301.0566122531891, score: 0.3161538461538462}
  32: {runtime: 298.76273798942566, score: 0.3353846153846154}
  33: {runtime: 304.83578300476074, score: 0.2976923076923077}
  34: {runtime: 303.2587032318115, score: 0.3161538461538462}
  35: {runtime: 305.6273009777069, score: 0.3046153846153846}
  36: {runtime: 299.2732846736908, score: 0.25153846153846154}
  37: {runtime: 288.0979588031769, score: 0.2915384615384615}
  38: {runtime: 288.31085538864136, score: 0.2692307692307692}
  39: {runtime: 303.97302079200745, score: 0.39615384615384613}
  40: {runtime: 304.690128326416, score: 0.37615384615384617}
  41: {runtime: 302.31218123435974, score: 0.42923076923076925}
  42: {runtime: 298.8675606250763, score: 0.41615384615384615}
  43: {runtime: 285.9785120487213, score: 0.4169230769230769}
  44: {runtime: 303.07228422164917, score: 0.36}
  45: {runtime: 302.890408039093, score: 0.32461538461538464}
  46: {runtime: 289.2748773097992, score: 0.4207692307692308}
  47: {runtime: 302.80784845352173, score: 0.32769230769230767}
  48: {runtime: 144.8184154033661, score: 0.2792307692307692}
  49: {runtime: 144.1505970954895, score: 0.40692307692307694}
  mean: 0.3398153846153846
  se: !!python/object/apply:numpy.core.multiarray.scalar
  - !!python/object/apply:numpy.dtype
    args: [f8, 0, 1]
    state: !!python/tuple [3, <, null, null, null, -1, -1, 0]
  - !!binary |
    wvMY6fCXgj8=
settings: {L: 50, argmaxer: quad_approx, argmaxer_name: quad_approx, classifier: KerasLogit,
  divide_evenly: false, env_name: SIS, evaluation_budget: 100, gamma: 0.9, number_of_replicates: 50,
  planning_depth: 25, policy_name: rollout, regressor: KerasRegressor, rollout_depth: 1,
  time_horizon: 25, treatment_budget: 3}
