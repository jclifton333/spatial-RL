results:
  0: {runtime: 32.46900510787964, score: 0.34923076923076923}
  1: {runtime: 32.61414694786072, score: 0.40307692307692305}
  2: {runtime: 32.48113131523132, score: 0.4623076923076923}
  3: {runtime: 32.3370566368103, score: 0.32}
  4: {runtime: 31.670655727386475, score: 0.35}
  5: {runtime: 32.200419902801514, score: 0.3853846153846154}
  6: {runtime: 32.33116626739502, score: 0.3776923076923077}
  7: {runtime: 32.15493440628052, score: 0.37846153846153846}
  8: {runtime: 32.581897020339966, score: 0.3576923076923077}
  9: {runtime: 31.848582983016968, score: 0.37461538461538463}
  10: {runtime: 32.34725499153137, score: 0.3253846153846154}
  11: {runtime: 32.29407548904419, score: 0.3569230769230769}
  12: {runtime: 32.209243059158325, score: 0.4169230769230769}
  13: {runtime: 32.25574350357056, score: 0.3169230769230769}
  14: {runtime: 32.206828355789185, score: 0.44846153846153847}
  15: {runtime: 32.26511859893799, score: 0.3984615384615385}
  16: {runtime: 32.398897886276245, score: 0.39692307692307693}
  17: {runtime: 32.10709023475647, score: 0.33153846153846156}
  18: {runtime: 32.391446113586426, score: 0.39615384615384613}
  19: {runtime: 31.85615062713623, score: 0.4453846153846154}
  20: {runtime: 32.33278799057007, score: 0.3484615384615385}
  21: {runtime: 31.993045568466187, score: 0.3269230769230769}
  22: {runtime: 31.826308727264404, score: 0.4976923076923077}
  23: {runtime: 32.316746950149536, score: 0.3830769230769231}
  24: {runtime: 32.28116512298584, score: 0.4123076923076923}
  25: {runtime: 32.534690618515015, score: 0.34}
  26: {runtime: 32.26843976974487, score: 0.4546153846153846}
  27: {runtime: 32.34687423706055, score: 0.4176923076923077}
  28: {runtime: 32.41170811653137, score: 0.4169230769230769}
  29: {runtime: 32.17431282997131, score: 0.44846153846153847}
  30: {runtime: 32.27719449996948, score: 0.28615384615384615}
  31: {runtime: 32.5236759185791, score: 0.3930769230769231}
  32: {runtime: 32.318570613861084, score: 0.37384615384615383}
  33: {runtime: 32.24595022201538, score: 0.33384615384615385}
  34: {runtime: 32.030930042266846, score: 0.3507692307692308}
  35: {runtime: 32.11222577095032, score: 0.3992307692307692}
  36: {runtime: 32.28738188743591, score: 0.36}
  37: {runtime: 31.945112705230713, score: 0.39}
  38: {runtime: 32.34713625907898, score: 0.38384615384615384}
  39: {runtime: 31.749529361724854, score: 0.3946153846153846}
  40: {runtime: 31.985920190811157, score: 0.3446153846153846}
  41: {runtime: 32.370217084884644, score: 0.42538461538461536}
  42: {runtime: 31.689993381500244, score: 0.42}
  43: {runtime: 31.66941809654236, score: 0.4553846153846154}
  44: {runtime: 32.52492713928223, score: 0.40384615384615385}
  45: {runtime: 32.39876651763916, score: 0.36153846153846153}
  46: {runtime: 32.438565731048584, score: 0.2746153846153846}
  47: {runtime: 31.580692768096924, score: 0.3892307692307692}
  48: {runtime: 14.354764699935913, score: 0.34076923076923077}
  49: {runtime: 14.32789397239685, score: 0.4623076923076923}
  mean: 0.3836153846153846
  se: !!python/object/apply:numpy.core.multiarray.scalar
  - !!python/object/apply:numpy.dtype
    args: [f8, 0, 1]
    state: !!python/tuple [3, <, null, null, null, -1, -1, 0]
  - !!binary |
    1rfy3sBQez8=
settings: {L: 50, argmaxer: quad_approx, argmaxer_name: quad_approx, classifier: KerasLogit,
  divide_evenly: false, env_name: sis, evaluation_budget: 100, gamma: 0.9, number_of_replicates: 50,
  planning_depth: 25, policy_name: rollout, regressor: KerasRegressor, rollout_depth: 0,
  time_horizon: 25, treatment_budget: 3}
