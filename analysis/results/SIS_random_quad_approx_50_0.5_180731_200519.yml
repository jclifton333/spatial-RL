results:
  0: {runtime: 0.8691864013671875, score: 0.553076923076923}
  1: {runtime: 0.8688693046569824, score: 0.5492307692307692}
  2: {runtime: 0.9404335021972656, score: 0.5338461538461539}
  3: {runtime: 0.8694193363189697, score: 0.5407692307692308}
  4: {runtime: 0.973945140838623, score: 0.5184615384615384}
  5: {runtime: 0.9746670722961426, score: 0.5092307692307693}
  6: {runtime: 0.96775221824646, score: 0.5392307692307692}
  7: {runtime: 0.9482884407043457, score: 0.5307692307692308}
  8: {runtime: 0.9614794254302979, score: 0.5438461538461539}
  9: {runtime: 0.9304213523864746, score: 0.5538461538461539}
  10: {runtime: 0.9713644981384277, score: 0.5361538461538462}
  11: {runtime: 0.9198849201202393, score: 0.5553846153846154}
  12: {runtime: 0.9642713069915771, score: 0.5230769230769231}
  13: {runtime: 0.9621257781982422, score: 0.5492307692307692}
  14: {runtime: 0.9804542064666748, score: 0.5430769230769231}
  15: {runtime: 0.8717679977416992, score: 0.5515384615384615}
  16: {runtime: 0.9667744636535645, score: 0.5361538461538462}
  17: {runtime: 0.9594924449920654, score: 0.5315384615384615}
  18: {runtime: 0.9535889625549316, score: 0.5330769230769231}
  19: {runtime: 0.9493241310119629, score: 0.5438461538461539}
  20: {runtime: 0.9411873817443848, score: 0.5330769230769231}
  21: {runtime: 0.9525930881500244, score: 0.5176923076923077}
  22: {runtime: 0.9576382637023926, score: 0.5292307692307693}
  23: {runtime: 0.9152257442474365, score: 0.5253846153846153}
  24: {runtime: 0.9398987293243408, score: 0.5415384615384615}
  25: {runtime: 0.9554200172424316, score: 0.5415384615384615}
  26: {runtime: 0.9772243499755859, score: 0.5638461538461539}
  27: {runtime: 0.9588274955749512, score: 0.5561538461538461}
  28: {runtime: 0.9102170467376709, score: 0.54}
  29: {runtime: 0.912949800491333, score: 0.5284615384615384}
  30: {runtime: 0.9778549671173096, score: 0.5307692307692308}
  31: {runtime: 0.9435281753540039, score: 0.5476923076923077}
  32: {runtime: 0.9277431964874268, score: 0.5138461538461538}
  33: {runtime: 0.9328169822692871, score: 0.5415384615384615}
  34: {runtime: 0.9669644832611084, score: 0.5076923076923077}
  35: {runtime: 0.9755730628967285, score: 0.49923076923076926}
  36: {runtime: 0.9360296726226807, score: 0.5330769230769231}
  37: {runtime: 0.9084961414337158, score: 0.5007692307692307}
  38: {runtime: 0.9424386024475098, score: 0.5746153846153846}
  39: {runtime: 0.8948655128479004, score: 0.5492307692307692}
  mean: 0.5362692307692308
  se: !!python/object/apply:numpy.core.multiarray.scalar
  - !!python/object/apply:numpy.dtype
    args: [f8, 0, 1]
    state: !!python/tuple [3, <, null, null, null, -1, -1, 0]
  - !!binary |
    p75MBT8XZT8=
settings: {L: 50, argmaxer: quad_approx, argmaxer_name: quad_approx, classifier: KerasLogit,
  divide_evenly: false, env_name: SIS, evaluation_budget: 100, gamma: 0.9, number_of_replicates: 40,
  planning_depth: 25, policy_name: random, regressor: KerasRegressor, rollout_depth: 1,
  time_horizon: 25, treatment_budget: 3}
