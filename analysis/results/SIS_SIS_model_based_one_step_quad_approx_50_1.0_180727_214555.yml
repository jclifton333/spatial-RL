results:
  0: {runtime: 8.558547019958496, score: 0.22230769230769232}
  1: {runtime: 6.605321884155273, score: 0.28307692307692306}
  2: {runtime: 9.624740600585938, score: 0.16076923076923078}
  3: {runtime: 6.694002866744995, score: 0.3607692307692308}
  4: {runtime: 6.698018312454224, score: 0.31846153846153846}
  5: {runtime: 9.76723337173462, score: 0.1976923076923077}
  6: {runtime: 8.961294651031494, score: 0.09076923076923077}
  7: {runtime: 6.882457256317139, score: 0.25846153846153846}
  8: {runtime: 9.372105121612549, score: 0.3223076923076923}
  9: {runtime: 6.4290711879730225, score: 0.3046153846153846}
  10: {runtime: 9.015969276428223, score: 0.19692307692307692}
  11: {runtime: 8.468931198120117, score: 0.32076923076923075}
  12: {runtime: 7.778549909591675, score: 0.2776923076923077}
  13: {runtime: 8.851482391357422, score: 0.28615384615384615}
  14: {runtime: 9.639657020568848, score: 0.25076923076923074}
  15: {runtime: 6.786804676055908, score: 0.27615384615384614}
  16: {runtime: 7.881655693054199, score: 0.4015384615384615}
  17: {runtime: 6.161922931671143, score: 0.3723076923076923}
  18: {runtime: 6.288730144500732, score: 0.3330769230769231}
  19: {runtime: 6.261003017425537, score: 0.4338461538461538}
  20: {runtime: 9.521443367004395, score: 0.30230769230769233}
  21: {runtime: 8.446862936019897, score: 0.27307692307692305}
  22: {runtime: 7.708153247833252, score: 0.2946153846153846}
  23: {runtime: 6.472087144851685, score: 0.36538461538461536}
  24: {runtime: 9.303353548049927, score: 0.2676923076923077}
  25: {runtime: 8.284438848495483, score: 0.11615384615384615}
  26: {runtime: 7.043165922164917, score: 0.24461538461538462}
  27: {runtime: 8.386548280715942, score: 0.30538461538461537}
  28: {runtime: 8.549236297607422, score: 0.3346153846153846}
  29: {runtime: 7.63741660118103, score: 0.3346153846153846}
  30: {runtime: 8.914169549942017, score: 0.25384615384615383}
  31: {runtime: 9.74969220161438, score: 0.19538461538461538}
  32: {runtime: 7.134154319763184, score: 0.2469230769230769}
  33: {runtime: 7.636643648147583, score: 0.36153846153846153}
  34: {runtime: 8.63871431350708, score: 0.32153846153846155}
  35: {runtime: 5.736488580703735, score: 0.48307692307692307}
  36: {runtime: 7.389172792434692, score: 0.28307692307692306}
  37: {runtime: 8.104135036468506, score: 0.38153846153846155}
  38: {runtime: 8.07616925239563, score: 0.31076923076923074}
  39: {runtime: 5.852980375289917, score: 0.47384615384615386}
  40: {runtime: 7.642519235610962, score: 0.2676923076923077}
  41: {runtime: 8.895662307739258, score: 0.28076923076923077}
  42: {runtime: 8.213901281356812, score: 0.31}
  43: {runtime: 6.163092136383057, score: 0.35307692307692307}
  44: {runtime: 8.647058486938477, score: 0.2946153846153846}
  45: {runtime: 8.304860353469849, score: 0.37}
  46: {runtime: 8.279330492019653, score: 0.2353846153846154}
  47: {runtime: 7.3638129234313965, score: 0.4369230769230769}
  48: {runtime: 5.413301229476929, score: 0.2561538461538462}
  49: {runtime: 5.553923845291138, score: 0.24153846153846154}
  mean: 0.2972923076923077
  se: !!python/object/apply:numpy.core.multiarray.scalar
  - !!python/object/apply:numpy.dtype
    args: [f8, 0, 1]
    state: !!python/tuple [3, <, null, null, null, -1, -1, 0]
  - !!binary |
    d8fGeZHEhj8=
settings: {L: 50, argmaxer: quad_approx, argmaxer_name: quad_approx, classifier: KerasLogit,
  divide_evenly: false, env_name: sis, evaluation_budget: 100, gamma: 0.9, number_of_replicates: 50,
  planning_depth: 25, policy_name: SIS_model_based_one_step, regressor: KerasRegressor,
  rollout_depth: 1, time_horizon: 25, treatment_budget: 3}
