results:
  0: {runtime: 0.3337547779083252, score: 0.36153846153846153}
  1: {runtime: 0.335432767868042, score: 0.4015384615384615}
  2: {runtime: 0.29427361488342285, score: 0.3076923076923077}
  3: {runtime: 0.33481287956237793, score: 0.3484615384615385}
  4: {runtime: 0.2804276943206787, score: 0.31384615384615383}
  5: {runtime: 0.22115445137023926, score: 0.25}
  6: {runtime: 0.21914410591125488, score: 0.3646153846153846}
  7: {runtime: 0.2684507369995117, score: 0.29615384615384616}
  8: {runtime: 0.25139594078063965, score: 0.3953846153846154}
  9: {runtime: 0.25527000427246094, score: 0.39076923076923076}
  10: {runtime: 0.26336169242858887, score: 0.38846153846153847}
  11: {runtime: 0.2657182216644287, score: 0.3515384615384615}
  12: {runtime: 0.21363186836242676, score: 0.39692307692307693}
  13: {runtime: 0.20894360542297363, score: 0.25769230769230766}
  14: {runtime: 0.2592353820800781, score: 0.2953846153846154}
  15: {runtime: 0.2101917266845703, score: 0.3823076923076923}
  16: {runtime: 0.20447278022766113, score: 0.32}
  17: {runtime: 0.21358704566955566, score: 0.33076923076923076}
  18: {runtime: 0.17528891563415527, score: 0.42923076923076925}
  19: {runtime: 0.26017045974731445, score: 0.3630769230769231}
  20: {runtime: 0.21148085594177246, score: 0.3576923076923077}
  21: {runtime: 0.24083995819091797, score: 0.4546153846153846}
  22: {runtime: 0.20966506004333496, score: 0.36846153846153845}
  23: {runtime: 0.2550699710845947, score: 0.41307692307692306}
  24: {runtime: 0.2436678409576416, score: 0.3576923076923077}
  25: {runtime: 0.2416234016418457, score: 0.32769230769230767}
  26: {runtime: 0.18486666679382324, score: 0.24615384615384617}
  27: {runtime: 0.18297147750854492, score: 0.4469230769230769}
  28: {runtime: 0.21065950393676758, score: 0.36230769230769233}
  29: {runtime: 0.1981983184814453, score: 0.4107692307692308}
  30: {runtime: 0.2329726219177246, score: 0.4246153846153846}
  31: {runtime: 0.2553408145904541, score: 0.29615384615384616}
  32: {runtime: 0.26244497299194336, score: 0.3176923076923077}
  33: {runtime: 0.21350955963134766, score: 0.3230769230769231}
  34: {runtime: 0.25080418586730957, score: 0.42615384615384616}
  35: {runtime: 0.25164175033569336, score: 0.3030769230769231}
  36: {runtime: 0.19792819023132324, score: 0.34076923076923077}
  37: {runtime: 0.20708465576171875, score: 0.4176923076923077}
  38: {runtime: 0.20415925979614258, score: 0.2815384615384615}
  39: {runtime: 0.20369601249694824, score: 0.43923076923076926}
  40: {runtime: 0.20060110092163086, score: 0.2823076923076923}
  41: {runtime: 0.25384020805358887, score: 0.3992307692307692}
  42: {runtime: 0.20139575004577637, score: 0.46153846153846156}
  43: {runtime: 0.1822986602783203, score: 0.41384615384615386}
  44: {runtime: 0.2110443115234375, score: 0.27384615384615385}
  45: {runtime: 0.20192599296569824, score: 0.39153846153846156}
  46: {runtime: 0.2417585849761963, score: 0.30230769230769233}
  47: {runtime: 0.23445868492126465, score: 0.38076923076923075}
  48: {runtime: 0.08787035942077637, score: 0.20307692307692307}
  49: {runtime: 0.08435869216918945, score: 0.35615384615384615}
  mean: 0.3545076923076923
  se: !!python/object/apply:numpy.core.multiarray.scalar
  - !!python/object/apply:numpy.dtype
    args: [f8, 0, 1]
    state: !!python/tuple [3, <, null, null, null, -1, -1, 0]
  - !!binary |
    F1AwmZM7gT8=
settings: {L: 50, argmaxer: quad_approx, argmaxer_name: quad_approx, classifier: KerasLogit,
  divide_evenly: false, env_name: sis, evaluation_budget: 100, gamma: 0.9, number_of_replicates: 50,
  planning_depth: 25, policy_name: random, regressor: KerasRegressor, rollout_depth: 1,
  time_horizon: 25, treatment_budget: 3}
