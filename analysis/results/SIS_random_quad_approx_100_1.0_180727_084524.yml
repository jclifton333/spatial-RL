results:
  0: {runtime: 0.40175414085388184, score: 0.4053846153846154}
  1: {runtime: 0.38490962982177734, score: 0.37884615384615383}
  2: {runtime: 0.3695533275604248, score: 0.4126923076923077}
  3: {runtime: 0.42713427543640137, score: 0.3403846153846154}
  4: {runtime: 0.33982300758361816, score: 0.4207692307692308}
  5: {runtime: 0.38872790336608887, score: 0.4503846153846154}
  6: {runtime: 0.35584020614624023, score: 0.4338461538461538}
  7: {runtime: 0.39220190048217773, score: 0.33653846153846156}
  8: {runtime: 0.3666839599609375, score: 0.4246153846153846}
  9: {runtime: 0.3751718997955322, score: 0.41307692307692306}
  10: {runtime: 0.36842894554138184, score: 0.385}
  11: {runtime: 0.3813629150390625, score: 0.41615384615384615}
  12: {runtime: 0.35645103454589844, score: 0.4530769230769231}
  13: {runtime: 0.4822824001312256, score: 0.42923076923076925}
  14: {runtime: 0.36426353454589844, score: 0.39884615384615385}
  15: {runtime: 0.41104722023010254, score: 0.43961538461538463}
  16: {runtime: 0.42116427421569824, score: 0.3769230769230769}
  17: {runtime: 0.3813779354095459, score: 0.41307692307692306}
  18: {runtime: 0.35260915756225586, score: 0.3942307692307692}
  19: {runtime: 0.36963891983032227, score: 0.385}
  20: {runtime: 0.35822391510009766, score: 0.40923076923076923}
  21: {runtime: 0.3532993793487549, score: 0.43846153846153846}
  22: {runtime: 0.3605232238769531, score: 0.4196153846153846}
  23: {runtime: 0.381244421005249, score: 0.4380769230769231}
  24: {runtime: 0.33556699752807617, score: 0.47}
  25: {runtime: 0.35012030601501465, score: 0.4196153846153846}
  26: {runtime: 0.35726094245910645, score: 0.33115384615384613}
  27: {runtime: 0.3369286060333252, score: 0.49230769230769234}
  28: {runtime: 0.3364698886871338, score: 0.3869230769230769}
  29: {runtime: 0.35299158096313477, score: 0.38961538461538464}
  30: {runtime: 0.36591148376464844, score: 0.42730769230769233}
  31: {runtime: 0.363020658493042, score: 0.36423076923076925}
  32: {runtime: 0.31261754035949707, score: 0.36923076923076925}
  33: {runtime: 0.4005253314971924, score: 0.4084615384615385}
  34: {runtime: 0.3737161159515381, score: 0.4146153846153846}
  35: {runtime: 0.3655202388763428, score: 0.455}
  36: {runtime: 0.2952299118041992, score: 0.33115384615384613}
  37: {runtime: 0.3866846561431885, score: 0.4746153846153846}
  38: {runtime: 0.34806394577026367, score: 0.43884615384615383}
  39: {runtime: 0.360060453414917, score: 0.4776923076923077}
  40: {runtime: 0.3083348274230957, score: 0.47884615384615387}
  41: {runtime: 0.3549478054046631, score: 0.345}
  42: {runtime: 0.3703289031982422, score: 0.3976923076923077}
  43: {runtime: 0.34470462799072266, score: 0.44884615384615384}
  44: {runtime: 0.3865981101989746, score: 0.4826923076923077}
  45: {runtime: 0.3453085422515869, score: 0.3426923076923077}
  46: {runtime: 0.3942990303039551, score: 0.41615384615384615}
  47: {runtime: 0.34897541999816895, score: 0.3688461538461538}
  48: {runtime: 0.26065802574157715, score: 0.35}
  49: {runtime: 0.24106550216674805, score: 0.45576923076923076}
  mean: 0.4110076923076924
  se: !!python/object/apply:numpy.core.multiarray.scalar
  - !!python/object/apply:numpy.dtype
    args: [f8, 0, 1]
    state: !!python/tuple [3, <, null, null, null, -1, -1, 0]
  - !!binary |
    NW5bmMRleD8=
settings: {L: 100, argmaxer: quad_approx, argmaxer_name: quad_approx, classifier: KerasLogit,
  divide_evenly: false, env_name: sis, evaluation_budget: 100, gamma: 0.9, number_of_replicates: 50,
  planning_depth: 25, policy_name: random, regressor: KerasRegressor, rollout_depth: 1,
  time_horizon: 25, treatment_budget: 5}
