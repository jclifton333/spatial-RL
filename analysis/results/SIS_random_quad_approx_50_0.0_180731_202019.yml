results:
  0: {runtime: 0.8788082599639893, score: 0.7284615384615385}
  1: {runtime: 0.9201581478118896, score: 0.7353846153846154}
  2: {runtime: 0.8964641094207764, score: 0.7361538461538462}
  3: {runtime: 0.8305613994598389, score: 0.7315384615384616}
  4: {runtime: 0.9125902652740479, score: 0.7123076923076923}
  5: {runtime: 0.9549684524536133, score: 0.73}
  6: {runtime: 1.007061243057251, score: 0.7323076923076923}
  7: {runtime: 1.0066843032836914, score: 0.7076923076923077}
  8: {runtime: 0.9299108982086182, score: 0.7376923076923076}
  9: {runtime: 0.9214766025543213, score: 0.7407692307692307}
  10: {runtime: 0.950364351272583, score: 0.7346153846153847}
  11: {runtime: 0.9518938064575195, score: 0.7376923076923076}
  12: {runtime: 0.9005875587463379, score: 0.7292307692307692}
  13: {runtime: 0.8933842182159424, score: 0.7284615384615385}
  14: {runtime: 0.9335577487945557, score: 0.7223076923076923}
  15: {runtime: 0.9196574687957764, score: 0.7330769230769231}
  16: {runtime: 1.0015382766723633, score: 0.7469230769230769}
  17: {runtime: 1.0006942749023438, score: 0.7461538461538462}
  18: {runtime: 0.8842282295227051, score: 0.7284615384615385}
  19: {runtime: 0.8790159225463867, score: 0.7361538461538462}
  20: {runtime: 0.8976397514343262, score: 0.7338461538461538}
  21: {runtime: 0.8394970893859863, score: 0.7230769230769231}
  22: {runtime: 0.8751204013824463, score: 0.7353846153846154}
  23: {runtime: 0.8454751968383789, score: 0.7392307692307692}
  24: {runtime: 0.8861076831817627, score: 0.7176923076923077}
  25: {runtime: 0.8315982818603516, score: 0.7338461538461538}
  26: {runtime: 0.9356253147125244, score: 0.7423076923076923}
  27: {runtime: 0.8364381790161133, score: 0.74}
  28: {runtime: 0.9926011562347412, score: 0.7315384615384616}
  29: {runtime: 0.9882240295410156, score: 0.73}
  30: {runtime: 0.8995134830474854, score: 0.6923076923076923}
  31: {runtime: 0.8825464248657227, score: 0.71}
  32: {runtime: 0.9153287410736084, score: 0.7269230769230769}
  33: {runtime: 0.9101138114929199, score: 0.7330769230769231}
  34: {runtime: 0.9326369762420654, score: 0.7176923076923077}
  35: {runtime: 0.890744686126709, score: 0.7361538461538462}
  36: {runtime: 0.9344124794006348, score: 0.7223076923076923}
  37: {runtime: 0.858403205871582, score: 0.7276923076923076}
  38: {runtime: 0.9324913024902344, score: 0.7453846153846154}
  39: {runtime: 0.8915860652923584, score: 0.7523076923076923}
  mean: 0.7306538461538461
  se: !!python/object/apply:numpy.core.multiarray.scalar
  - !!python/object/apply:numpy.dtype
    args: [f8, 0, 1]
    state: !!python/tuple [3, <, null, null, null, -1, -1, 0]
  - !!binary |
    mwlj+r2QXT8=
settings: {L: 50, argmaxer: quad_approx, argmaxer_name: quad_approx, classifier: KerasLogit,
  divide_evenly: false, env_name: SIS, evaluation_budget: 100, gamma: 0.9, number_of_replicates: 40,
  planning_depth: 25, policy_name: random, regressor: KerasRegressor, rollout_depth: 1,
  time_horizon: 25, treatment_budget: 3}
