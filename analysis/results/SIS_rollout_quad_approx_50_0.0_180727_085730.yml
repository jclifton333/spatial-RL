results:
  0: {runtime: 31.5955491065979, score: 0.30153846153846153}
  1: {runtime: 32.36768865585327, score: 0.4046153846153846}
  2: {runtime: 31.91012668609619, score: 0.4461538461538462}
  3: {runtime: 32.30082082748413, score: 0.31153846153846154}
  4: {runtime: 31.651137590408325, score: 0.14384615384615385}
  5: {runtime: 31.628040075302124, score: 0.3415384615384615}
  6: {runtime: 31.59388542175293, score: 0.2792307692307692}
  7: {runtime: 31.768455266952515, score: 0.3984615384615385}
  8: {runtime: 31.654897689819336, score: 0.28076923076923077}
  9: {runtime: 32.08550477027893, score: 0.38384615384615384}
  10: {runtime: 32.422468185424805, score: 0.1453846153846154}
  11: {runtime: 31.6538245677948, score: 0.22923076923076924}
  12: {runtime: 32.17942667007446, score: 0.4330769230769231}
  13: {runtime: 31.321362733840942, score: 0.26}
  14: {runtime: 32.091996908187866, score: 0.4153846153846154}
  15: {runtime: 31.02442240715027, score: 0.34307692307692306}
  16: {runtime: 30.804516315460205, score: 0.35615384615384615}
  17: {runtime: 31.270519733428955, score: 0.20923076923076922}
  18: {runtime: 31.528725624084473, score: 0.35923076923076924}
  19: {runtime: 31.711102724075317, score: 0.38846153846153847}
  20: {runtime: 32.41406273841858, score: 0.16538461538461538}
  21: {runtime: 31.6925630569458, score: 0.38769230769230767}
  22: {runtime: 31.85726499557495, score: 0.4553846153846154}
  23: {runtime: 31.624407052993774, score: 0.3269230769230769}
  24: {runtime: 32.548171043395996, score: 0.30230769230769233}
  25: {runtime: 31.833834648132324, score: 0.33}
  26: {runtime: 31.63655734062195, score: 0.4276923076923077}
  27: {runtime: 31.615331411361694, score: 0.35923076923076924}
  28: {runtime: 31.59369421005249, score: 0.4023076923076923}
  29: {runtime: 31.712740421295166, score: 0.4546153846153846}
  30: {runtime: 31.591956853866577, score: 0.32}
  31: {runtime: 31.966556072235107, score: 0.34692307692307695}
  32: {runtime: 31.750829696655273, score: 0.38076923076923075}
  33: {runtime: 33.63898968696594, score: 0.3161538461538462}
  34: {runtime: 31.01159930229187, score: 0.2592307692307692}
  35: {runtime: 31.83127474784851, score: 0.35846153846153844}
  36: {runtime: 31.958006858825684, score: 0.2946153846153846}
  37: {runtime: 31.753607273101807, score: 0.38}
  38: {runtime: 31.758897304534912, score: 0.3992307692307692}
  39: {runtime: 32.103678941726685, score: 0.32461538461538464}
  40: {runtime: 32.86982989311218, score: 0.23307692307692307}
  41: {runtime: 32.09609770774841, score: 0.4153846153846154}
  42: {runtime: 31.235363721847534, score: 0.42923076923076925}
  43: {runtime: 31.596041440963745, score: 0.39692307692307693}
  44: {runtime: 32.17341208457947, score: 0.30153846153846153}
  45: {runtime: 31.40305471420288, score: 0.33615384615384614}
  46: {runtime: 31.565279483795166, score: 0.20384615384615384}
  47: {runtime: 32.593971490859985, score: 0.33615384615384614}
  48: {runtime: 14.918894052505493, score: 0.26384615384615384}
  49: {runtime: 14.653775215148926, score: 0.3830769230769231}
  mean: 0.33443076923076925
  se: !!python/object/apply:numpy.core.multiarray.scalar
  - !!python/object/apply:numpy.dtype
    args: [f8, 0, 1]
    state: !!python/tuple [3, <, null, null, null, -1, -1, 0]
  - !!binary |
    AOGFsnGVhj8=
settings: {L: 50, argmaxer: quad_approx, argmaxer_name: quad_approx, classifier: KerasLogit,
  divide_evenly: false, env_name: sis, evaluation_budget: 100, gamma: 0.9, number_of_replicates: 50,
  planning_depth: 25, policy_name: rollout, regressor: KerasRegressor, rollout_depth: 0,
  time_horizon: 25, treatment_budget: 3}
