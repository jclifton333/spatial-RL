results:
  0: {runtime: 0.307384729385376, score: 0.3992307692307692}
  1: {runtime: 0.37581777572631836, score: 0.35923076923076924}
  2: {runtime: 0.37087512016296387, score: 0.39807692307692305}
  3: {runtime: 0.376178503036499, score: 0.32846153846153847}
  4: {runtime: 0.2509753704071045, score: 0.4219230769230769}
  5: {runtime: 0.3660423755645752, score: 0.4196153846153846}
  6: {runtime: 0.30856776237487793, score: 0.4276923076923077}
  7: {runtime: 0.37913990020751953, score: 0.32769230769230767}
  8: {runtime: 0.37834620475769043, score: 0.4238461538461539}
  9: {runtime: 0.3650939464569092, score: 0.3973076923076923}
  10: {runtime: 0.4639456272125244, score: 0.36038461538461536}
  11: {runtime: 0.24175691604614258, score: 0.4096153846153846}
  12: {runtime: 0.35874414443969727, score: 0.43115384615384617}
  13: {runtime: 0.3551654815673828, score: 0.4346153846153846}
  14: {runtime: 0.3361542224884033, score: 0.37538461538461537}
  15: {runtime: 0.3460047245025635, score: 0.3842307692307692}
  16: {runtime: 0.38604140281677246, score: 0.3219230769230769}
  17: {runtime: 0.39101314544677734, score: 0.3853846153846154}
  18: {runtime: 0.464479923248291, score: 0.3526923076923077}
  19: {runtime: 0.32800769805908203, score: 0.3496153846153846}
  20: {runtime: 0.32946181297302246, score: 0.3426923076923077}
  21: {runtime: 0.35704970359802246, score: 0.4096153846153846}
  22: {runtime: 0.388141393661499, score: 0.39576923076923076}
  23: {runtime: 0.3556098937988281, score: 0.4369230769230769}
  24: {runtime: 0.44124531745910645, score: 0.455}
  25: {runtime: 0.2925891876220703, score: 0.38076923076923075}
  26: {runtime: 0.35298991203308105, score: 0.3273076923076923}
  27: {runtime: 0.21637821197509766, score: 0.46}
  28: {runtime: 0.36397862434387207, score: 0.3873076923076923}
  29: {runtime: 0.3564460277557373, score: 0.32884615384615384}
  30: {runtime: 0.289691686630249, score: 0.4326923076923077}
  31: {runtime: 0.2663605213165283, score: 0.3523076923076923}
  32: {runtime: 0.35863709449768066, score: 0.35615384615384615}
  33: {runtime: 0.3585779666900635, score: 0.38461538461538464}
  34: {runtime: 0.4715085029602051, score: 0.38846153846153847}
  35: {runtime: 0.272702693939209, score: 0.4015384615384615}
  36: {runtime: 0.3268158435821533, score: 0.3119230769230769}
  37: {runtime: 0.34035444259643555, score: 0.4796153846153846}
  38: {runtime: 0.45690226554870605, score: 0.42846153846153845}
  39: {runtime: 0.31200289726257324, score: 0.4684615384615385}
  40: {runtime: 0.2685976028442383, score: 0.4469230769230769}
  41: {runtime: 0.47524452209472656, score: 0.29346153846153844}
  42: {runtime: 0.345674991607666, score: 0.3680769230769231}
  43: {runtime: 0.3635551929473877, score: 0.41}
  44: {runtime: 0.36835598945617676, score: 0.4707692307692308}
  45: {runtime: 0.3468475341796875, score: 0.3296153846153846}
  46: {runtime: 0.3333439826965332, score: 0.40692307692307694}
  47: {runtime: 0.38134002685546875, score: 0.34076923076923077}
  48: {runtime: 0.17580461502075195, score: 0.33615384615384614}
  49: {runtime: 0.2639799118041992, score: 0.41923076923076924}
  mean: 0.3891692307692307
  se: !!python/object/apply:numpy.core.multiarray.scalar
  - !!python/object/apply:numpy.dtype
    args: [f8, 0, 1]
    state: !!python/tuple [3, <, null, null, null, -1, -1, 0]
  - !!binary |
    nRb0nWRzej8=
settings: {L: 100, argmaxer: quad_approx, argmaxer_name: quad_approx, classifier: KerasLogit,
  divide_evenly: false, env_name: sis, evaluation_budget: 100, gamma: 0.9, number_of_replicates: 50,
  planning_depth: 25, policy_name: random, regressor: KerasRegressor, rollout_depth: 1,
  time_horizon: 25, treatment_budget: 5}
