results:
  0: {runtime: 9586.287528038025, score: 0.10384615384615385}
  1: {runtime: 9987.899495840073, score: 0.3569230769230769}
  2: {runtime: 9549.119257926941, score: 0.4553846153846154}
  3: {runtime: 9988.278495788574, score: 0.10923076923076923}
  4: {runtime: 9548.958292245865, score: 0.047692307692307694}
  5: {runtime: 9981.076341867447, score: 0.11076923076923077}
  6: {runtime: 9973.138043880463, score: 0.37615384615384617}
  7: {runtime: 9584.537793636322, score: 0.26384615384615384}
  8: {runtime: 9973.517614603043, score: 0.38153846153846155}
  9: {runtime: 9529.590772867203, score: 0.21384615384615385}
  10: {runtime: 9542.738652467728, score: 0.04461538461538461}
  11: {runtime: 9769.594522714615, score: 0.04}
  12: {runtime: 9961.89529967308, score: 0.40692307692307694}
  13: {runtime: 9962.354734897614, score: 0.16846153846153847}
  14: {runtime: 9490.343517541885, score: 0.4330769230769231}
  15: {runtime: 9488.319750547409, score: 0.3953846153846154}
  16: {runtime: 9967.077028274536, score: 0.10538461538461538}
  17: {runtime: 9947.993322134018, score: 0.09923076923076923}
  18: {runtime: 9965.576370239258, score: 0.3161538461538462}
  19: {runtime: 9937.346175193787, score: 0.2453846153846154}
  20: {runtime: 9965.527284860611, score: 0.05692307692307692}
  21: {runtime: 9485.140361785889, score: 0.18769230769230769}
  22: {runtime: 9477.173545598984, score: 0.44846153846153847}
  23: {runtime: 9472.328543901443, score: 0.23615384615384616}
  24: {runtime: 9493.066417694092, score: 0.39615384615384613}
  25: {runtime: 9507.811852931976, score: 0.06230769230769231}
  26: {runtime: 9926.670215845108, score: 0.15153846153846154}
  27: {runtime: 9954.02159333229, score: 0.10538461538461538}
  28: {runtime: 9468.323378324509, score: 0.39076923076923076}
  29: {runtime: 9491.881408452988, score: 0.43538461538461537}
  30: {runtime: 9472.872958421707, score: 0.28615384615384615}
  31: {runtime: 9489.102504491806, score: 0.09615384615384616}
  32: {runtime: 9473.705818891525, score: 0.3261538461538461}
  33: {runtime: 9482.954100847244, score: 0.32769230769230767}
  34: {runtime: 9475.55297422409, score: 0.39153846153846156}
  35: {runtime: 9938.605803489685, score: 0.08461538461538462}
  36: {runtime: 9469.769409179688, score: 0.33615384615384614}
  37: {runtime: 9926.416039466858, score: 0.2676923076923077}
  38: {runtime: 9927.657495737076, score: 0.39153846153846156}
  39: {runtime: 9923.787581443787, score: 0.3446153846153846}
  40: {runtime: 9909.493285179138, score: 0.3384615384615385}
  41: {runtime: 9913.548815011978, score: 0.15384615384615385}
  42: {runtime: 9439.847595453262, score: 0.3930769230769231}
  43: {runtime: 9916.912391901016, score: 0.34}
  44: {runtime: 9443.874946594238, score: 0.26461538461538464}
  45: {runtime: 9891.396360874176, score: 0.3646153846153846}
  46: {runtime: 9904.1687707901, score: 0.11923076923076924}
  47: {runtime: 9872.059666395187, score: 0.44076923076923075}
  48: {runtime: 4673.188381910324, score: 0.2676923076923077}
  49: {runtime: 4658.518457889557, score: 0.31384615384615383}
  mean: 0.2598615384615385
  se: !!python/object/apply:numpy.core.multiarray.scalar
  - !!python/object/apply:numpy.dtype
    args: [f8, 0, 1]
    state: !!python/tuple [3, <, null, null, null, -1, -1, 0]
  - !!binary |
    n/+GRoMMkz8=
settings: {L: 50, argmaxer: quad_approx, argmaxer_name: quad_approx, classifier: KerasLogit,
  divide_evenly: false, env_name: sis, evaluation_budget: 100, gamma: 0.9, number_of_replicates: 50,
  planning_depth: 25, policy_name: SIS_model_based, regressor: KerasRegressor, rollout_depth: 0,
  time_horizon: 25, treatment_budget: 3}
