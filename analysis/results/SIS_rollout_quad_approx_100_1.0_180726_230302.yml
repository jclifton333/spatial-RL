results:
  0: {runtime: 646.6011481285095, score: 0.37461538461538463}
  1: {runtime: 642.2341949939728, score: 0.42846153846153845}
  2: {runtime: 641.6439299583435, score: 0.40923076923076923}
  3: {runtime: 642.9323077201843, score: 0.38461538461538464}
  4: {runtime: 642.8473784923553, score: 0.45884615384615385}
  5: {runtime: 639.8607866764069, score: 0.41}
  6: {runtime: 647.7508020401001, score: 0.4153846153846154}
  7: {runtime: 640.3312928676605, score: 0.43538461538461537}
  8: {runtime: 647.935239315033, score: 0.42730769230769233}
  9: {runtime: 640.748494386673, score: 0.4065384615384615}
  10: {runtime: 644.4344177246094, score: 0.37153846153846154}
  11: {runtime: 637.8310573101044, score: 0.4596153846153846}
  12: {runtime: 641.476576089859, score: 0.39653846153846156}
  13: {runtime: 642.2947981357574, score: 0.4176923076923077}
  14: {runtime: 639.645646572113, score: 0.3280769230769231}
  15: {runtime: 639.8811681270599, score: 0.4}
  16: {runtime: 641.5621030330658, score: 0.38153846153846155}
  17: {runtime: 640.4085664749146, score: 0.4442307692307692}
  18: {runtime: 646.6895234584808, score: 0.38769230769230767}
  19: {runtime: 640.8974187374115, score: 0.405}
  20: {runtime: 642.8790459632874, score: 0.32076923076923075}
  21: {runtime: 643.4528367519379, score: 0.42115384615384616}
  22: {runtime: 644.2441213130951, score: 0.4015384615384615}
  23: {runtime: 646.7857904434204, score: 0.4623076923076923}
  24: {runtime: 641.5093994140625, score: 0.45615384615384613}
  25: {runtime: 641.8598175048828, score: 0.38153846153846155}
  26: {runtime: 642.3818898200989, score: 0.3573076923076923}
  27: {runtime: 643.6001048088074, score: 0.43115384615384617}
  28: {runtime: 648.6167902946472, score: 0.42230769230769233}
  29: {runtime: 640.1341187953949, score: 0.4542307692307692}
  30: {runtime: 642.8671894073486, score: 0.38461538461538464}
  31: {runtime: 640.1556267738342, score: 0.3842307692307692}
  32: {runtime: 642.7366971969604, score: 0.3426923076923077}
  33: {runtime: 644.0339894294739, score: 0.36}
  34: {runtime: 645.2062561511993, score: 0.4203846153846154}
  35: {runtime: 639.9265170097351, score: 0.495}
  36: {runtime: 643.557520866394, score: 0.34692307692307695}
  37: {runtime: 638.4844279289246, score: 0.4419230769230769}
  38: {runtime: 646.8446364402771, score: 0.4430769230769231}
  39: {runtime: 644.8507125377655, score: 0.44153846153846155}
  40: {runtime: 645.9208829402924, score: 0.4876923076923077}
  41: {runtime: 645.4660663604736, score: 0.33115384615384613}
  42: {runtime: 648.2507045269012, score: 0.39115384615384613}
  43: {runtime: 647.3358764648438, score: 0.4196153846153846}
  44: {runtime: 645.2953317165375, score: 0.38961538461538464}
  45: {runtime: 646.3705010414124, score: 0.425}
  46: {runtime: 644.6920554637909, score: 0.38769230769230767}
  47: {runtime: 648.1766641139984, score: 0.42846153846153845}
  48: {runtime: 306.9941473007202, score: 0.4296153846153846}
  49: {runtime: 306.0285441875458, score: 0.4469230769230769}
  mean: 0.40896153846153843
  se: !!python/object/apply:numpy.core.multiarray.scalar
  - !!python/object/apply:numpy.dtype
    args: [f8, 0, 1]
    state: !!python/tuple [3, <, null, null, null, -1, -1, 0]
  - !!binary |
    ChY5lLq3dj8=
settings: {L: 100, argmaxer: quad_approx, argmaxer_name: quad_approx, classifier: KerasLogit,
  divide_evenly: false, env_name: sis, evaluation_budget: 100, gamma: 0.9, number_of_replicates: 50,
  planning_depth: 25, policy_name: fqi, regressor: KerasRegressor, rollout_depth: 1,
  time_horizon: 25, treatment_budget: 5}
