results:
  0: {runtime: 1.2899432182312012, score: 0.46784313725490195}
  1: {runtime: 1.295755386352539, score: 0.44058823529411767}
  2: {runtime: 1.2570903301239014, score: 0.45803921568627454}
  3: {runtime: 1.3048222064971924, score: 0.41568627450980394}
  4: {runtime: 1.2503328323364258, score: 0.4711764705882353}
  5: {runtime: 1.2566821575164795, score: 0.4584313725490196}
  6: {runtime: 1.2508668899536133, score: 0.47941176470588237}
  7: {runtime: 1.2978882789611816, score: 0.42705882352941177}
  8: {runtime: 1.2074592113494873, score: 0.4680392156862745}
  9: {runtime: 1.2689182758331299, score: 0.4531372549019608}
  10: {runtime: 1.2342803478240967, score: 0.43941176470588234}
  11: {runtime: 1.2330856323242188, score: 0.4707843137254902}
  12: {runtime: 1.2221810817718506, score: 0.486078431372549}
  13: {runtime: 1.208846092224121, score: 0.46627450980392154}
  14: {runtime: 1.220489263534546, score: 0.4323529411764706}
  15: {runtime: 1.2106821537017822, score: 0.4288235294117647}
  16: {runtime: 1.2213795185089111, score: 0.41843137254901963}
  17: {runtime: 1.3223061561584473, score: 0.4429411764705882}
  18: {runtime: 1.2023561000823975, score: 0.432156862745098}
  19: {runtime: 1.1948342323303223, score: 0.4496078431372549}
  20: {runtime: 1.198349952697754, score: 0.44019607843137254}
  21: {runtime: 1.1915209293365479, score: 0.45431372549019605}
  22: {runtime: 1.2416205406188965, score: 0.4623529411764706}
  23: {runtime: 1.2278833389282227, score: 0.4872549019607843}
  24: {runtime: 1.1449975967407227, score: 0.49392156862745096}
  25: {runtime: 1.257573127746582, score: 0.4449019607843137}
  26: {runtime: 1.1437427997589111, score: 0.4288235294117647}
  27: {runtime: 1.175814151763916, score: 0.5062745098039215}
  28: {runtime: 1.1637439727783203, score: 0.42137254901960786}
  29: {runtime: 1.0439255237579346, score: 0.38745098039215686}
  30: {runtime: 1.1210074424743652, score: 0.46509803921568627}
  31: {runtime: 1.2230618000030518, score: 0.4080392156862745}
  32: {runtime: 1.1761343479156494, score: 0.43823529411764706}
  33: {runtime: 1.179105281829834, score: 0.46215686274509804}
  34: {runtime: 1.1637651920318604, score: 0.4633333333333333}
  35: {runtime: 1.2117512226104736, score: 0.44666666666666666}
  36: {runtime: 1.1809945106506348, score: 0.36411764705882355}
  37: {runtime: 1.2261159420013428, score: 0.5115686274509804}
  38: {runtime: 1.283677339553833, score: 0.43960784313725493}
  39: {runtime: 1.1368441581726074, score: 0.5172549019607843}
  mean: 0.45123039215686267
  se: !!python/object/apply:numpy.core.multiarray.scalar
  - !!python/object/apply:numpy.dtype
    args: [f8, 0, 1]
    state: !!python/tuple [3, <, null, null, null, -1, -1, 0]
  - !!binary |
    /OcZJIUJdD8=
settings: {L: 100, argmaxer: quad_approx, argmaxer_name: quad_approx, classifier: SKLogit,
  divide_evenly: false, env_name: SIS, evaluation_budget: 100, gamma: 0.9, number_of_replicates: 40,
  planning_depth: 50, policy_name: random, regressor: KerasRegressor, rollout_depth: 1,
  time_horizon: 50, treatment_budget: 5}
