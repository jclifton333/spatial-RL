results:
  0: {runtime: 0.9638745784759521, score: 0.7284615384615385}
  1: {runtime: 0.9673471450805664, score: 0.7353846153846154}
  2: {runtime: 0.9424467086791992, score: 0.7361538461538462}
  3: {runtime: 0.950188159942627, score: 0.7315384615384616}
  4: {runtime: 0.9254212379455566, score: 0.7123076923076923}
  5: {runtime: 0.9757270812988281, score: 0.73}
  6: {runtime: 0.9596333503723145, score: 0.7323076923076923}
  7: {runtime: 0.9757599830627441, score: 0.7076923076923077}
  8: {runtime: 0.949669361114502, score: 0.7376923076923076}
  9: {runtime: 0.9819591045379639, score: 0.7407692307692307}
  10: {runtime: 0.972858190536499, score: 0.7346153846153847}
  11: {runtime: 0.9666826725006104, score: 0.7376923076923076}
  12: {runtime: 0.9729855060577393, score: 0.7292307692307692}
  13: {runtime: 0.9792389869689941, score: 0.7284615384615385}
  14: {runtime: 0.9916188716888428, score: 0.7223076923076923}
  15: {runtime: 0.9776232242584229, score: 0.7330769230769231}
  16: {runtime: 0.9683258533477783, score: 0.7469230769230769}
  17: {runtime: 0.9689664840698242, score: 0.7461538461538462}
  18: {runtime: 0.9594457149505615, score: 0.7284615384615385}
  19: {runtime: 0.9666216373443604, score: 0.7361538461538462}
  20: {runtime: 0.9660952091217041, score: 0.7338461538461538}
  21: {runtime: 0.9942681789398193, score: 0.7230769230769231}
  22: {runtime: 0.9440946578979492, score: 0.7353846153846154}
  23: {runtime: 0.9207150936126709, score: 0.7392307692307692}
  24: {runtime: 0.9348809719085693, score: 0.7176923076923077}
  25: {runtime: 0.9476373195648193, score: 0.7338461538461538}
  26: {runtime: 0.9479992389678955, score: 0.7423076923076923}
  27: {runtime: 0.9239284992218018, score: 0.74}
  28: {runtime: 0.9538426399230957, score: 0.7315384615384616}
  29: {runtime: 0.9154362678527832, score: 0.73}
  30: {runtime: 0.9947257041931152, score: 0.6923076923076923}
  31: {runtime: 0.8661878108978271, score: 0.71}
  32: {runtime: 0.8184881210327148, score: 0.7269230769230769}
  33: {runtime: 0.8263463973999023, score: 0.7330769230769231}
  34: {runtime: 0.8180737495422363, score: 0.7176923076923077}
  35: {runtime: 0.9043912887573242, score: 0.7361538461538462}
  36: {runtime: 0.8499631881713867, score: 0.7223076923076923}
  37: {runtime: 0.9340317249298096, score: 0.7276923076923076}
  38: {runtime: 0.9022328853607178, score: 0.7453846153846154}
  39: {runtime: 0.9936015605926514, score: 0.7523076923076923}
  mean: 0.7306538461538461
  se: !!python/object/apply:numpy.core.multiarray.scalar
  - !!python/object/apply:numpy.dtype
    args: [f8, 0, 1]
    state: !!python/tuple [3, <, null, null, null, -1, -1, 0]
  - !!binary |
    mwlj+r2QXT8=
settings: {L: 50, argmaxer: quad_approx, argmaxer_name: quad_approx, classifier: KerasLogit,
  divide_evenly: false, env_name: SIS, evaluation_budget: 100, gamma: 0.9, number_of_replicates: 40,
  planning_depth: 25, policy_name: random, regressor: KerasRegressor, rollout_depth: 1,
  time_horizon: 25, treatment_budget: 3}
