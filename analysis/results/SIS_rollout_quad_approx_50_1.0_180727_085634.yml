results:
  0: {runtime: 308.9483308792114, score: 0.2823076923076923}
  1: {runtime: 307.8001000881195, score: 0.3484615384615385}
  2: {runtime: 303.6516752243042, score: 0.4276923076923077}
  3: {runtime: 280.63226318359375, score: 0.31384615384615383}
  4: {runtime: 279.1739184856415, score: 0.32769230769230767}
  5: {runtime: 279.82554602622986, score: 0.45615384615384613}
  6: {runtime: 282.11809253692627, score: 0.40076923076923077}
  7: {runtime: 306.24994134902954, score: 0.4076923076923077}
  8: {runtime: 304.42168831825256, score: 0.3323076923076923}
  9: {runtime: 279.33171916007996, score: 0.38846153846153847}
  10: {runtime: 279.6666429042816, score: 0.3046153846153846}
  11: {runtime: 279.5031476020813, score: 0.3223076923076923}
  12: {runtime: 307.2420885562897, score: 0.3484615384615385}
  13: {runtime: 306.67471265792847, score: 0.39}
  14: {runtime: 278.36368799209595, score: 0.42923076923076925}
  15: {runtime: 296.53414487838745, score: 0.3930769230769231}
  16: {runtime: 279.13485884666443, score: 0.3892307692307692}
  17: {runtime: 278.3570532798767, score: 0.34}
  18: {runtime: 279.4376664161682, score: 0.4492307692307692}
  19: {runtime: 279.1235234737396, score: 0.4807692307692308}
  20: {runtime: 279.11914110183716, score: 0.39153846153846156}
  21: {runtime: 278.54658555984497, score: 0.3723076923076923}
  22: {runtime: 279.1231858730316, score: 0.4330769230769231}
  23: {runtime: 297.7970588207245, score: 0.3576923076923077}
  24: {runtime: 278.1374235153198, score: 0.4023076923076923}
  25: {runtime: 278.0760838985443, score: 0.3069230769230769}
  26: {runtime: 304.2142753601074, score: 0.33615384615384614}
  27: {runtime: 278.54093837738037, score: 0.3630769230769231}
  28: {runtime: 306.59932231903076, score: 0.4369230769230769}
  29: {runtime: 278.0995044708252, score: 0.48307692307692307}
  30: {runtime: 279.38499450683594, score: 0.40923076923076923}
  31: {runtime: 277.0181391239166, score: 0.30538461538461537}
  32: {runtime: 298.6010642051697, score: 0.3192307692307692}
  33: {runtime: 297.87104988098145, score: 0.3376923076923077}
  34: {runtime: 277.9188313484192, score: 0.40615384615384614}
  35: {runtime: 278.1866717338562, score: 0.43}
  36: {runtime: 277.19228982925415, score: 0.3230769230769231}
  37: {runtime: 275.94172859191895, score: 0.36923076923076925}
  38: {runtime: 305.6124703884125, score: 0.3792307692307692}
  39: {runtime: 305.3708028793335, score: 0.44076923076923075}
  40: {runtime: 304.8209710121155, score: 0.4330769230769231}
  41: {runtime: 277.40600848197937, score: 0.4753846153846154}
  42: {runtime: 279.1955683231354, score: 0.33384615384615385}
  43: {runtime: 296.0993330478668, score: 0.4207692307692308}
  44: {runtime: 277.7299294471741, score: 0.3507692307692308}
  45: {runtime: 295.9410343170166, score: 0.41923076923076924}
  46: {runtime: 303.8305609226227, score: 0.4492307692307692}
  47: {runtime: 301.2109558582306, score: 0.43538461538461537}
  48: {runtime: 147.97462701797485, score: 0.38461538461538464}
  49: {runtime: 146.71534514427185, score: 0.42923076923076925}
  mean: 0.38533846153846146
  se: !!python/object/apply:numpy.core.multiarray.scalar
  - !!python/object/apply:numpy.dtype
    args: [f8, 0, 1]
    state: !!python/tuple [3, <, null, null, null, -1, -1, 0]
  - !!binary |
    vQruRDPkfT8=
settings: {L: 50, argmaxer: quad_approx, argmaxer_name: quad_approx, classifier: KerasLogit,
  divide_evenly: false, env_name: sis, evaluation_budget: 100, gamma: 0.9, number_of_replicates: 50,
  planning_depth: 25, policy_name: rollout, regressor: KerasRegressor, rollout_depth: 1,
  time_horizon: 25, treatment_budget: 3}
