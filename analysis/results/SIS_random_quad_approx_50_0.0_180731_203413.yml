results:
  0: {runtime: 0.8810610771179199, score: 0.36153846153846153}
  1: {runtime: 0.8909728527069092, score: 0.4015384615384615}
  2: {runtime: 0.8898293972015381, score: 0.3076923076923077}
  3: {runtime: 0.8988912105560303, score: 0.3484615384615385}
  4: {runtime: 0.8629176616668701, score: 0.31384615384615383}
  5: {runtime: 0.9643988609313965, score: 0.25}
  6: {runtime: 0.960073709487915, score: 0.3646153846153846}
  7: {runtime: 0.9312021732330322, score: 0.29615384615384616}
  8: {runtime: 0.9320101737976074, score: 0.3953846153846154}
  9: {runtime: 0.9143931865692139, score: 0.39076923076923076}
  10: {runtime: 0.8522136211395264, score: 0.38846153846153847}
  11: {runtime: 0.9203741550445557, score: 0.3515384615384615}
  12: {runtime: 0.9079065322875977, score: 0.39692307692307693}
  13: {runtime: 1.0038046836853027, score: 0.25769230769230766}
  14: {runtime: 0.8808228969573975, score: 0.2953846153846154}
  15: {runtime: 0.9992733001708984, score: 0.3823076923076923}
  16: {runtime: 0.9214863777160645, score: 0.32}
  17: {runtime: 0.9424245357513428, score: 0.33076923076923076}
  18: {runtime: 0.8785295486450195, score: 0.42923076923076925}
  19: {runtime: 0.9708540439605713, score: 0.3630769230769231}
  20: {runtime: 1.0136268138885498, score: 0.3576923076923077}
  21: {runtime: 0.9641225337982178, score: 0.4546153846153846}
  22: {runtime: 0.9463973045349121, score: 0.36846153846153845}
  23: {runtime: 0.9999308586120605, score: 0.41307692307692306}
  24: {runtime: 0.972874641418457, score: 0.3576923076923077}
  25: {runtime: 0.9518029689788818, score: 0.32769230769230767}
  26: {runtime: 0.9280779361724854, score: 0.24615384615384617}
  27: {runtime: 0.9931654930114746, score: 0.4469230769230769}
  28: {runtime: 0.9913723468780518, score: 0.36230769230769233}
  29: {runtime: 0.912311315536499, score: 0.4107692307692308}
  30: {runtime: 0.965604305267334, score: 0.4246153846153846}
  31: {runtime: 0.9698286056518555, score: 0.29615384615384616}
  32: {runtime: 0.996680498123169, score: 0.3176923076923077}
  33: {runtime: 0.8938305377960205, score: 0.3230769230769231}
  34: {runtime: 0.8465020656585693, score: 0.42615384615384616}
  35: {runtime: 0.8571498394012451, score: 0.3030769230769231}
  36: {runtime: 0.9953923225402832, score: 0.34076923076923077}
  37: {runtime: 0.8958108425140381, score: 0.4176923076923077}
  38: {runtime: 0.8872649669647217, score: 0.2815384615384615}
  39: {runtime: 0.946906328201294, score: 0.43923076923076926}
  mean: 0.35651923076923075
  se: !!python/object/apply:numpy.core.multiarray.scalar
  - !!python/object/apply:numpy.dtype
    args: [f8, 0, 1]
    state: !!python/tuple [3, <, null, null, null, -1, -1, 0]
  - !!binary |
    aZM0hpDEgT8=
settings: {L: 50, argmaxer: quad_approx, argmaxer_name: quad_approx, classifier: KerasLogit,
  divide_evenly: false, env_name: SIS, evaluation_budget: 100, gamma: 0.9, number_of_replicates: 40,
  planning_depth: 25, policy_name: random, regressor: KerasRegressor, rollout_depth: 1,
  time_horizon: 25, treatment_budget: 3}
