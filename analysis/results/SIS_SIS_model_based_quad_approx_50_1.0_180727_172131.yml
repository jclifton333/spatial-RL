results:
  0: {runtime: 10064.766113042831, score: 0.25461538461538463}
  1: {runtime: 10028.518431663513, score: 0.39}
  2: {runtime: 10048.061686754227, score: 0.35307692307692307}
  3: {runtime: 9719.193518161774, score: 0.36615384615384616}
  4: {runtime: 9688.559866905212, score: 0.2684615384615385}
  5: {runtime: 10017.539934396744, score: 0.35307692307692307}
  6: {runtime: 9681.316980838776, score: 0.38}
  7: {runtime: 10029.644525527954, score: 0.41}
  8: {runtime: 10010.197048425674, score: 0.3192307692307692}
  9: {runtime: 9669.993145942688, score: 0.4169230769230769}
  10: {runtime: 9672.151980400085, score: 0.2723076923076923}
  11: {runtime: 10015.043043851852, score: 0.4146153846153846}
  12: {runtime: 9660.929552793503, score: 0.47307692307692306}
  13: {runtime: 9999.156717061996, score: 0.22846153846153847}
  14: {runtime: 10016.17431640625, score: 0.39384615384615385}
  15: {runtime: 9663.740575790405, score: 0.4146153846153846}
  16: {runtime: 10024.684561491013, score: 0.38076923076923075}
  17: {runtime: 9631.408473014832, score: 0.40076923076923077}
  18: {runtime: 10030.13852262497, score: 0.11461538461538462}
  19: {runtime: 9623.927012681961, score: 0.43}
  20: {runtime: 10025.731555223465, score: 0.3869230769230769}
  21: {runtime: 10004.02517580986, score: 0.34692307692307695}
  22: {runtime: 10011.772107124329, score: 0.49615384615384617}
  23: {runtime: 10025.309895515442, score: 0.09769230769230769}
  24: {runtime: 9995.009845495224, score: 0.30153846153846153}
  25: {runtime: 9631.020662784576, score: 0.29846153846153844}
  26: {runtime: 9627.319159030914, score: 0.39692307692307693}
  27: {runtime: 9626.74348783493, score: 0.31461538461538463}
  28: {runtime: 9640.456996440887, score: 0.32846153846153847}
  29: {runtime: 9606.537038087845, score: 0.5076923076923077}
  30: {runtime: 9990.53773188591, score: 0.31846153846153846}
  31: {runtime: 9612.657645702362, score: 0.38384615384615384}
  32: {runtime: 9986.606588602066, score: 0.42538461538461536}
  33: {runtime: 10007.782648324966, score: 0.3384615384615385}
  34: {runtime: 10016.440950632095, score: 0.32076923076923075}
  35: {runtime: 10011.191517353058, score: 0.4430769230769231}
  36: {runtime: 10009.97143626213, score: 0.27384615384615385}
  37: {runtime: 9981.225419998169, score: 0.47}
  38: {runtime: 9606.577559947968, score: 0.15076923076923077}
  39: {runtime: 10026.92250418663, score: 0.36846153846153845}
  40: {runtime: 9751.685733318329, score: 0.33}
  41: {runtime: 9993.34485912323, score: 0.4230769230769231}
  42: {runtime: 10035.256628990173, score: 0.18461538461538463}
  43: {runtime: 9979.206297636032, score: 0.3823076923076923}
  44: {runtime: 9584.369280576706, score: 0.20846153846153845}
  45: {runtime: 9566.013219833374, score: 0.47846153846153844}
  46: {runtime: 10016.376677513123, score: 0.22076923076923077}
  47: {runtime: 9540.066847324371, score: 0.47}
  48: {runtime: 4619.929074048996, score: 0.2323076923076923}
  49: {runtime: 4621.5568108558655, score: 0.4369230769230769}
  mean: 0.34740000000000004
  se: !!python/object/apply:numpy.core.multiarray.scalar
  - !!python/object/apply:numpy.dtype
    args: [f8, 0, 1]
    state: !!python/tuple [3, <, null, null, null, -1, -1, 0]
  - !!binary |
    J5H5vI/Giz8=
settings: {L: 50, argmaxer: quad_approx, argmaxer_name: quad_approx, classifier: KerasLogit,
  divide_evenly: false, env_name: sis, evaluation_budget: 100, gamma: 0.9, number_of_replicates: 50,
  planning_depth: 25, policy_name: SIS_model_based, regressor: KerasRegressor, rollout_depth: 1,
  time_horizon: 25, treatment_budget: 3}
