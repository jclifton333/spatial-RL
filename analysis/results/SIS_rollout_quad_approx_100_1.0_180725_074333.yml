results:
  0: {runtime: 64.59874296188354, score: 0.3992307692307692}
  1: {runtime: 66.99833011627197, score: 0.33692307692307694}
  2: {runtime: 65.44116306304932, score: 0.4073076923076923}
  3: {runtime: 66.52774453163147, score: 0.425}
  4: {runtime: 66.90152668952942, score: 0.4469230769230769}
  5: {runtime: 65.84607243537903, score: 0.40384615384615385}
  6: {runtime: 65.98608350753784, score: 0.21423076923076922}
  7: {runtime: 65.19588303565979, score: 0.3953846153846154}
  8: {runtime: 64.69409823417664, score: 0.41192307692307695}
  9: {runtime: 66.50432562828064, score: 0.3726923076923077}
  10: {runtime: 66.49326491355896, score: 0.4442307692307692}
  11: {runtime: 66.65092158317566, score: 0.44}
  12: {runtime: 67.93404340744019, score: 0.37384615384615383}
  13: {runtime: 66.01679921150208, score: 0.4646153846153846}
  14: {runtime: 66.0333833694458, score: 0.3823076923076923}
  15: {runtime: 66.38622713088989, score: 0.4642307692307692}
  16: {runtime: 66.28829050064087, score: 0.42923076923076925}
  17: {runtime: 65.08089423179626, score: 0.3523076923076923}
  18: {runtime: 67.91626119613647, score: 0.4226923076923077}
  19: {runtime: 67.00347423553467, score: 0.3773076923076923}
  20: {runtime: 65.8833556175232, score: 0.4076923076923077}
  21: {runtime: 65.57031965255737, score: 0.3853846153846154}
  22: {runtime: 66.37602829933167, score: 0.4226923076923077}
  23: {runtime: 67.26887702941895, score: 0.37}
  24: {runtime: 66.92018151283264, score: 0.49153846153846154}
  25: {runtime: 67.07745170593262, score: 0.4646153846153846}
  26: {runtime: 67.01205444335938, score: 0.32884615384615384}
  27: {runtime: 67.7664680480957, score: 0.3696153846153846}
  28: {runtime: 66.68340849876404, score: 0.43}
  29: {runtime: 68.69630455970764, score: 0.41115384615384615}
  30: {runtime: 67.1470456123352, score: 0.3557692307692308}
  31: {runtime: 68.2831654548645, score: 0.3565384615384615}
  32: {runtime: 67.61876082420349, score: 0.3211538461538462}
  33: {runtime: 67.05760025978088, score: 0.405}
  34: {runtime: 68.46688580513, score: 0.37038461538461537}
  35: {runtime: 67.19161701202393, score: 0.4307692307692308}
  36: {runtime: 68.53515768051147, score: 0.36115384615384616}
  37: {runtime: 68.08103656768799, score: 0.44076923076923075}
  38: {runtime: 68.58927178382874, score: 0.4480769230769231}
  39: {runtime: 67.70116066932678, score: 0.39615384615384613}
  40: {runtime: 69.00419974327087, score: 0.39653846153846156}
  41: {runtime: 68.07905650138855, score: 0.335}
  42: {runtime: 68.70089769363403, score: 0.4176923076923077}
  43: {runtime: 68.74255681037903, score: 0.4123076923076923}
  44: {runtime: 68.07800936698914, score: 0.4207692307692308}
  45: {runtime: 68.1680519580841, score: 0.3596153846153846}
  46: {runtime: 65.72550010681152, score: 0.3376923076923077}
  47: {runtime: 68.19831228256226, score: 0.3596153846153846}
  48: {runtime: 28.071428060531616, score: 0.3792307692307692}
  49: {runtime: 28.024904489517212, score: 0.37153846153846154}
  mean: 0.39443076923076925
  se: !!python/object/apply:numpy.core.multiarray.scalar
  - !!python/object/apply:numpy.dtype
    args: [f8, 0, 1]
    state: !!python/tuple [3, <, null, null, null, -1, -1, 0]
  - !!binary |
    4q19EWkpez8=
settings: {L: 100, argmaxer: quad_approx, argmaxer_name: quad_approx, classifier: KerasLogit,
  divide_evenly: false, env_name: sis, evaluation_budget: 100, gamma: 0.9, number_of_replicates: 50,
  planning_depth: 25, policy_name: rollout, regressor: RandomForestRegressor, rollout_depth: 0,
  time_horizon: 25, treatment_budget: 5}
