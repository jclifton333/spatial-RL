results:
  0: {runtime: 27.331006288528442, score: 0.3984615384615385}
  1: {runtime: 27.606770753860474, score: 0.3953846153846154}
  2: {runtime: 27.33661723136902, score: 0.5230769230769231}
  3: {runtime: 27.41603708267212, score: 0.34692307692307695}
  4: {runtime: 27.084587574005127, score: 0.2746153846153846}
  5: {runtime: 26.911496877670288, score: 0.39692307692307693}
  6: {runtime: 27.185829877853394, score: 0.46153846153846156}
  7: {runtime: 26.438849687576294, score: 0.3930769230769231}
  8: {runtime: 27.25948405265808, score: 0.3892307692307692}
  9: {runtime: 27.417540073394775, score: 0.42230769230769233}
  10: {runtime: 26.979527473449707, score: 0.3676923076923077}
  11: {runtime: 27.24282932281494, score: 0.31461538461538463}
  12: {runtime: 26.869786262512207, score: 0.3830769230769231}
  13: {runtime: 27.231395483016968, score: 0.3192307692307692}
  14: {runtime: 27.06727170944214, score: 0.4946153846153846}
  15: {runtime: 26.718188762664795, score: 0.39153846153846156}
  16: {runtime: 26.3803768157959, score: 0.3946153846153846}
  17: {runtime: 26.404991149902344, score: 0.36615384615384616}
  18: {runtime: 26.87066626548767, score: 0.40615384615384614}
  19: {runtime: 26.69306516647339, score: 0.4230769230769231}
  20: {runtime: 26.89294195175171, score: 0.3376923076923077}
  21: {runtime: 26.93924117088318, score: 0.43153846153846154}
  22: {runtime: 27.05307650566101, score: 0.5069230769230769}
  23: {runtime: 27.09334111213684, score: 0.3730769230769231}
  24: {runtime: 26.656405925750732, score: 0.3607692307692308}
  25: {runtime: 27.12587571144104, score: 0.3630769230769231}
  26: {runtime: 26.65108036994934, score: 0.4623076923076923}
  27: {runtime: 26.800265550613403, score: 0.4246153846153846}
  28: {runtime: 27.43337368965149, score: 0.4}
  29: {runtime: 26.21721839904785, score: 0.46}
  30: {runtime: 26.912246227264404, score: 0.37}
  31: {runtime: 26.83062744140625, score: 0.3415384615384615}
  32: {runtime: 26.874202251434326, score: 0.35923076923076924}
  33: {runtime: 26.932599782943726, score: 0.3038461538461538}
  34: {runtime: 27.103605031967163, score: 0.3669230769230769}
  35: {runtime: 26.73357391357422, score: 0.41307692307692306}
  36: {runtime: 26.425169944763184, score: 0.40692307692307694}
  37: {runtime: 26.3493709564209, score: 0.39615384615384613}
  38: {runtime: 25.989511013031006, score: 0.3869230769230769}
  39: {runtime: 26.43373680114746, score: 0.36615384615384616}
  mean: 0.3923269230769231
  se: !!python/object/apply:numpy.core.multiarray.scalar
  - !!python/object/apply:numpy.dtype
    args: [f8, 0, 1]
    state: !!python/tuple [3, <, null, null, null, -1, -1, 0]
  - !!binary |
    APjQDOXLgD8=
settings: {L: 50, argmaxer: quad_approx, argmaxer_name: quad_approx, classifier: KerasLogit,
  divide_evenly: false, env_name: SIS, evaluation_budget: 100, gamma: 0.9, number_of_replicates: 40,
  planning_depth: 25, policy_name: one_step, regressor: KerasRegressor, rollout_depth: 1,
  time_horizon: 25, treatment_budget: 3}
